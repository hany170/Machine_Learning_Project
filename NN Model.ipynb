{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b67c4294",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input, MaxPooling2D, Flatten,Conv2D,Reshape, Conv1D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras.metrics import Recall, Precision\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import shutil\n",
    "import sys\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.applications.resnet50 import  preprocess_input\n",
    "from keras.utils import to_categorical\n",
    "import os\n",
    "import cv2 as cv\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d370bb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"C:/Users/Asus/University/Machine learning/Face_splittedData/train\"\n",
    "test_dir =  \"C:/Users/Asus/University/Machine learning/Face_splittedData/test\"\n",
    "# Set up the image dimensions\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "\n",
    " \n",
    "\n",
    "# Define a function to preprocess the images\n",
    "def preprocess_images(data_dir):\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for class_name in os.listdir(data_dir):\n",
    "        class_dir = os.path.join(data_dir, class_name)\n",
    "        if os.path.isdir(class_dir):\n",
    "            for file_name in os.listdir(class_dir):\n",
    "                if file_name.endswith('.jpg'):\n",
    "                    img_path = os.path.join(class_dir, file_name)\n",
    "                    img = cv2.imread(img_path)\n",
    "                    img = cv2.resize(img, (img_height, img_width))\n",
    "                    img= img_to_array(img)\n",
    "                    img=preprocess_input(img)\n",
    "                    X.append(img)\n",
    "                    y.append(class_name)\n",
    "                    \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    # Normalize the data using mean and standard deviation and we applied the normalization before the oversamling to prevent data leakage\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X.reshape(X.shape[0], -1))\n",
    "    X = X.reshape(-1, img_height, img_width, 3)\n",
    "    \n",
    "    # Apply SMOTE to balance the classes(oversambling as our data is imbalanced)\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X.reshape(X.shape[0], -1), y)\n",
    "    X_resampled = X_resampled.reshape(-1, img_height, img_width, 3)\n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "    # Perform label encoding on the target variable (labels)\n",
    "#     label_encoder = LabelEncoder()\n",
    "#     y_resampled = label_encoder.fit_transform(y_resampled)\n",
    "    \n",
    "    return X_resampled, y_resampled\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "383cfe7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the training data\n",
    "train_X, train_y = preprocess_images(train_dir)\n",
    "\n",
    "# Preprocess the testing data\n",
    "test_X, test_y = preprocess_images(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "31d295bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the trainX shape is: (1346, 224, 224, 3)\n",
      "the testx shape is (506, 224, 224, 3)\n",
      "the ytrain shape is: (1346,)\n",
      "the ytest shape is: (506,)\n"
     ]
    }
   ],
   "source": [
    "print(\"the trainX shape is:\",train_X.shape)\n",
    "print(\"the testx shape is\",test_X.shape)\n",
    "print(\"the ytrain shape is:\",train_y.shape)\n",
    "print(\"the ytest shape is:\",test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c4f32cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#flattening the images\n",
    "train_X = train_X.reshape(train_X.shape[0], -1)\n",
    "test_X = test_X.reshape(test_X.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "48bbdf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(224*224*3,)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "14f8a94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['accuracy',\n",
    "           tf.keras.metrics.Precision(name='precision'),\n",
    "           tf.keras.metrics.Recall(name='recall')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6f3614c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "train_y_encoded = label_encoder.fit_transform(train_y)\n",
    "test_y_encoded = label_encoder.transform(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2a75c34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "53e01051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "22/22 [==============================] - 4s 100ms/step - loss: 1.7062 - accuracy: 0.9361 - precision: 0.9361 - recall: 0.9361 - val_loss: 0.7731 - val_accuracy: 0.9763 - val_precision: 0.9689 - val_recall: 0.9842\n",
      "Epoch 2/10\n",
      "22/22 [==============================] - 2s 75ms/step - loss: 0.3568 - accuracy: 0.9903 - precision: 0.9911 - recall: 0.9896 - val_loss: 0.1700 - val_accuracy: 0.9901 - val_precision: 0.9844 - val_recall: 0.9960\n",
      "Epoch 3/10\n",
      "22/22 [==============================] - 2s 73ms/step - loss: 0.1305 - accuracy: 0.9963 - precision: 0.9941 - recall: 0.9985 - val_loss: 0.1177 - val_accuracy: 0.9960 - val_precision: 1.0000 - val_recall: 0.9921\n",
      "Epoch 4/10\n",
      "22/22 [==============================] - 2s 71ms/step - loss: 0.0017 - accuracy: 0.9985 - precision: 0.9985 - recall: 0.9985 - val_loss: 0.1919 - val_accuracy: 0.9941 - val_precision: 0.9960 - val_recall: 0.9921\n",
      "Epoch 5/10\n",
      "22/22 [==============================] - 2s 71ms/step - loss: 0.1071 - accuracy: 0.9941 - precision: 0.9926 - recall: 0.9955 - val_loss: 0.0742 - val_accuracy: 0.9941 - val_precision: 0.9921 - val_recall: 0.9960\n",
      "Epoch 6/10\n",
      "22/22 [==============================] - 2s 69ms/step - loss: 0.1470 - accuracy: 0.9963 - precision: 0.9955 - recall: 0.9970 - val_loss: 0.0484 - val_accuracy: 0.9980 - val_precision: 1.0000 - val_recall: 0.9960\n",
      "Epoch 7/10\n",
      "22/22 [==============================] - 2s 70ms/step - loss: 0.2610 - accuracy: 0.9933 - precision: 0.9926 - recall: 0.9941 - val_loss: 0.1702 - val_accuracy: 0.9941 - val_precision: 1.0000 - val_recall: 0.9881\n",
      "Epoch 8/10\n",
      "22/22 [==============================] - 2s 70ms/step - loss: 0.1643 - accuracy: 0.9948 - precision: 0.9912 - recall: 0.9985 - val_loss: 0.2037 - val_accuracy: 0.9921 - val_precision: 1.0000 - val_recall: 0.9842\n",
      "Epoch 9/10\n",
      "22/22 [==============================] - 2s 70ms/step - loss: 0.3296 - accuracy: 0.9933 - precision: 0.9940 - recall: 0.9926 - val_loss: 0.0346 - val_accuracy: 0.9960 - val_precision: 1.0000 - val_recall: 0.9921\n",
      "Epoch 10/10\n",
      "22/22 [==============================] - 2s 70ms/step - loss: 0.5377 - accuracy: 0.9963 - precision: 0.9970 - recall: 0.9955 - val_loss: 0.1318 - val_accuracy: 0.9941 - val_precision: 1.0000 - val_recall: 0.9881\n"
     ]
    }
   ],
   "source": [
    "#khalena elepochs w el batches w el optimizer zy b3dena\n",
    "history = model.fit(train_X,train_y_encoded,batch_size=64 ,epochs=10,\n",
    "                        validation_data=(test_X, test_y_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6bdb53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
